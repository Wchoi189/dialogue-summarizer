Dialogue Summarization | 일상 대화 요약
학교 생활, 직장, 치료, 쇼핑, 여가, 여행 등 광범위한 일상 생활 중 하는 대화들에 대해 요약합니다.

[공유] 텍스트 데이터에서 인사이트를 얻기
1. 텍스트 데이터 
텍스트 데이터는 기존의 숫자로 구성된 데이터와 달리, 인사이트를 얻기가 상대적으로 어려울 수 있습니다. 하지만, 가설을 만들거나 조건을 주어 텍스트들의 패턴을 파악해볼 수 있답니다. 이번 대회의 데이터는 여러 사람들과 나눈 데이터를 바탕으로 요약문을 만드는 데이터이므로, 사람별로 발화가 구분되어 있을거고, 나눈 대화의 주제나 길이 등도 분석해볼 수 있겠죠? 

2. 텍스트 데이터 살펴보기
그럼 훈련 데이터를 먼저 확인해보도록 하겠습니다. 

훈련 데이터를 먼저 살펴보니, dialogue 와 summary 로 데이터가 구성되어있네요! 각각의 대화에 대한 고유 index 가 fname 에 저장되어 있습니다. dialogue 가 대화에 참여한 발화자들이 나눈 전체 대화이고, 각각의 대화는 \n 으로 구분되어 있네요! 실제 하나의 대화를 출력해보면 아래와 같습니다. 

실제로 대화문들은 구어체로 구성되어 있는데, 요약문은 문어체로 구성되어 있는 걸 볼 수 있습니다! 

이 대화를 각 turn 별로 구분해서 보면 좀 더 분석하기가 쉽겠네요? 대화를 시작하는 첫 turn 에는 안부를 묻거나 본인이 누구인지, 주요 대화의 주제가 등장하는 대화가 이뤄지고 있습니다. 

그렇다면 평가 데이터는 어떻게 구성되어 있을까요? 

평가 데이터는 하나의 대화에 3가지의 요약문이 부착되어 있어, 실제 평가를 할 때 모델이 다양한 응답을 반환하더라도 적절히 채점될 수 있게 되어있습니다. 

우리는 모델을 학습할 것이기 때문에 max_length 를 확인하는 부분도 필요하겠죠? 물론 사용할 tokenizer 를 적용해 토큰화를 한 후에 max_length 를 찍어보는 게 좋겠지만, 일단 음절을 바탕으로 확인해보겠습니다. 

이를 바탕으로 대화, 요약문의 max_length를 적절히 선택하면 되겠죠?

이제 우리는 데이터들을 가지고 여러 방법들을 사용하여 인사이트를 얻어보겠습니다. 

3. 텍스트 데이터 전처리 
대회에서 주어진 데이터들은 잘 정제가 되어있지만, 문어체로 대화가 이루어지고 있기 때문에 자음이나 모음만으로 구성된 (ㅋㅋ, ㅇㅇ 등) 경우가 있는지 확인해보고, 이를 대체하는 방법까지 알아보려 합니다. 자/모음으로 구성된 경우가 아니더라도, 데이터에서 특정한 값이 포함되는지 찾거나 대체할 때 이 방법을 사용할 수 있습니다. 

4. 워드클라우드 
데이터 정제를 완료했으면, 데이터에서 많이 등장하는 단어들을 확인하여 주요 대화 주제 등을 확인합니다. 물론 단어 빈도만으로도 가능하지만, 시각화를 해서 좀 더 보기 좋게 만들어보겠습니다. 

모든 대화를 다 사용하면 조사가 바뀔 때 마다 각자 다르게 인식하기 때문에, 우선 대화 중  단어 토큰화, 명사 추출을 한 후 보겠습니다. 

실제로 모델을 학습할 때는 토큰화를 진행하여 사용하지만, 지금은 인사이트를 얻기 위해서 하기 때문에 명사만 추출한 결과를 사용하도록 하겠습니다. 이를 바탕으로 가장 많이 등장한 단어를 워드 클라우드로 시각화해보면 다음과 같습니다. 

 

많이 등장한 단어들 중 우리, 정말과 같은 대화 주제별로 다른 단어가 아니라 일반적으로 대화에 많이 쓰는 단어들이 많이 등장하여 인사이트를 얻기가 조금 힘듭니다. 이런 경우를 방지하려고 TF-IDF(Term Frequency - Inverse Document Frequency) 라는 방법을 씁니다. 이는 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지를 나타내는 수치인데, 이 방법을 사용하게 되면 여러 문서에서 공통적으로 자주 등장하는 단어보다는 특정 문서 내에서 더 중요하게 판단되는 단어를 추출해줍니다. 

5. 개인정보 마스킹 부분 확인 
해당 데이터셋에는 개인정보가 포함되어 있었어서, 이 개인정보들을 마스킹 하여 제공합니다. 

이렇게 8가지의 정보들을 마스킹 해두었는데, 두 개의 # 사이에 어떤 정보가 마스킹 되어있는지를 표시합니다. 

이런 패턴을 가지고 있는 값들을 추출하기 위해서는 정규표현식을 사용할 수 있습니다. 

이렇게 정규표현식을 적용한 결과를 확인해보면 다음과 같습니다. 

발화자를 구분하는 토큰도 #PersonN# 두 개의 # 사이에 Person 번호를 넣어 구성하고 있네요. 두 개의 # 사이에 숫자로 끝나는 값이 들어있으면 추출하는 명령어를 주면 대화에 포함된 발화자가 몇 명인지 확인할 수 있겠습니다. 

이렇게 정규표현식을 잘 활용하면 원하는 텍스트들의 패턴을 확인하여 추출할 수 있습니다. 이렇게 마스킹 한 값들을 tokenizer 에 special token으로 포함시키려면 다음과 같은 방법을 사용할 수 있습니다. 

추가된 토큰들의 index 를 확인하면 다음과 같이 잘 추가되었음을 확인할 수 있네요! 

6. 토론 
이렇게 텍스트 데이터에서는 다양한 정보를 추출할 수 있습니다. 어떤 특정한 단어나 패턴을 파악하여 정제하는 등의 다양한 시도를 해보면서 모델의 성능을 높일 수 있는 방법들을 생각해봅시다! 