# =============================================================================
# configs/experiment/baseline.yaml
# =============================================================================
# @package _global_
# Baseline experiment configuration - ONLY overrides needed

# Override only what's different from main config
training:
  max_epochs: 8
  optimizer:
    lr: 5e-6

generation:
  max_length: 60
  repetition_penalty: 1.3

wandb:
  tags: ["baseline", "kobart", "conservative"]
  notes: "Baseline experiment with conservative settings"

# =============================================================================
# configs/experiment/aggressive.yaml  
# =============================================================================
# @package _global_
# More aggressive training experiment

training:
  max_epochs: 12
  optimizer:
    lr: 1e-5  # Higher learning rate
  
  early_stopping:
    patience: 3  # More patience

generation:
  max_length: 80  # Allow longer summaries
  repetition_penalty: 1.4
  length_penalty: 0.9

wandb:
  tags: ["aggressive", "kobart", "higher-lr"]
  notes: "Aggressive training with higher learning rate"

# =============================================================================
# configs/experiment/debug.yaml
# =============================================================================
# @package _global_
# Debug experiment with fast settings

data:
  batch_size: 4
  eval_batch_size: 4

training:
  max_epochs: 2
  fast_dev_run: false
  limit_train_batches: 0.1
  limit_val_batches: 0.1

generation:
  num_beams: 2  # Faster generation

wandb:
  offline: true  # Don't log to wandb
  tags: ["debug", "fast"]

logging:
  level: "DEBUG"

# =============================================================================
# configs/experiment/production.yaml
# =============================================================================
# @package _global_
# Production experiment with optimal settings

data:
  batch_size: 32
  eval_batch_size: 64
  num_workers: 16

training:
  max_epochs: 15
  optimizer:
    lr: 3e-6  # Very conservative
  
  early_stopping:
    patience: 4
    min_delta: 0.005

generation:
  max_length: 50
  num_beams: 5  # Higher quality
  repetition_penalty: 1.2
  length_penalty: 0.7

wandb:
  tags: ["production", "final", "optimized"]
  notes: "Production settings for final model"